version: '3.8'

services:
  llm_router:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm_router
    ports:
      - "7440:7440"
    environment:
      - ROUTER_HOST=0.0.0.0
      - ROUTER_PORT=7440
      - ROUTER_REQUIRE_API_KEY=false
      - ROUTER_LOG_LEVEL=INFO
      - ROUTER_CACHE_DIR=/tmp/llm_router_cache
      - ROUTER_ENABLE_OLLAMA_FALLBACK=true
      - ROUTER_OLLAMA_API_BASE=http://host.docker.internal:11434
      - ROUTER_CORS_ALLOW_ALL=true
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - TOGETHER_API_KEY=${TOGETHER_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
      - COHERE_API_KEY=${COHERE_API_KEY:-}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY:-}
      - XAI_API_KEY=${XAI_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    volumes:
      - llm_router_cache:/tmp/llm_router_cache
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7440/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - llm_router_network
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm_router_frontend
    ports:
      - "3000:3000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    networks:
      - llm_router_network

volumes:
  llm_router_cache:
    driver: local

networks:
  llm_router_network:
    driver: bridge
